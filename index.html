<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>ISL Recognition</title>
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;600;700&display=swap">

<style>
    body {
        font-family: 'Inter', sans-serif;
        margin: 0;
        background: #fafafa;
        color: #222;
        text-align: center;
    }
    header {
        width: 100%;
        padding: 20px 60px;
        display: flex;
        justify-content: space-between;
        align-items: center;
        background: white;
        border-bottom: 1px solid #eee;
    }
    header h2 { font-weight: 600; }
    nav a {
        margin: 0 12px;
        text-decoration: none;
        color: #444;
        font-weight: 500;
    }
    .hero {
        padding: 90px 20px;
    }
    .hero h1 {
        font-size: 42px;
        font-weight: 700;
    }
    .subtext {
        max-width: 700px;
        margin: 15px auto;
        color: #555;
        font-size: 18px;
    }
    .button-primary {
        padding: 16px 30px;
        background: #1976ff;
        border-radius: 8px;
        border: none;
        color: white;
        font-size: 18px;
        cursor: pointer;
        display: inline-flex;
        align-items: center;
        gap: 10px;
    }
    #camera-section {
        margin-top: 40px;
        padding: 50px 20px;
    }
    video {
        width: 500px;
        height: 380px;
        background: black;
        border-radius: 12px;
    }
    .prediction-box {
        margin-top: 20px;
        font-size: 20px;
        font-weight: 600;
        color: #1976ff;
    }
</style>
</head>

<body>

<header>
    <h2>ISL Recognition</h2>
    <nav>
        <a href="#camera-section">Try It</a>
        <a href="#how">How It Works</a>
        <a href="#">Resources</a>
    </nav>
</header>

<section class="hero">
    <h1>Recognize Indian Sign Language in Real-Time</h1>
    <p class="subtext">
        Use AI-driven gesture recognition with your webcam! Powered by TensorFlow.js
        to make ISL communication more accessible for everyone.
    </p>
    <button class="button-primary" onclick="startCamera()">
        ðŸ“· Try It Now
    </button>
</section>

<section id="camera-section">
    <h2>Live Recognition</h2>
    <video id="webcam" autoplay playsinline></video>
    <div class="prediction-box" id="prediction">Current Prediction: ---</div>
</section>

<section id="how" style="padding:70px 20px; background:white;">
    <h2>How It Works</h2><br>
    âœ… Allow Camera Access<br><br>
    âœ‹ Show Your Gesture Clearly<br><br>
    âš¡ See Instant Predictions
</section>

<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
<script src="https://cdn.jsdelivr.net/npm/@teachablemachine/image"></script>

<script>
    const URL = "https://teachablemachine.withgoogle.com/models/qWODT4HYw/";
    let model, webcam, maxPredictions;

    async function loadModel() {
        const modelURL = URL + "model.json";
        const metadataURL = URL + "metadata.json";
        model = await tmImage.load(modelURL, metadataURL);
        maxPredictions = model.getTotalClasses();
    }

    async function startCamera() {
        await loadModel();
        webcam = new tmImage.Webcam(500, 380, true);
        await webcam.setup();
        await webcam.play();
        document.getElementById("webcam").srcObject = webcam.webcam.stream;

        window.requestAnimationFrame(loop);
    }

    async function loop() {
        webcam.update();
        await predict();
        window.requestAnimationFrame(loop);
    }

    async function predict() {
        const prediction = await model.predict(webcam.canvas);
        let highest = prediction[0];
        prediction.forEach(p => {
            if (p.probability > highest.probability) highest = p;
        });
        document.getElementById("prediction").innerText =
            "Current Prediction: " + highest.className;
    }
</script>

</body>
</html>
